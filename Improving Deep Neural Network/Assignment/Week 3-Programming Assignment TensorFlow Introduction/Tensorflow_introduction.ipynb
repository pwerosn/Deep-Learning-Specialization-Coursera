{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow\n",
    "\n",
    "Welcome to this week's programming assignment! Up until now, you've always used Numpy to build neural networks, but this week you'll explore a deep learning framework that allows you to build neural networks more easily. Machine learning frameworks like TensorFlow, PaddlePaddle, Torch, Caffe, Keras, and many others can speed up your machine learning development significantly. TensorFlow 2.3 has made significant improvements over its predecessor, some of which you'll encounter and implement here!\n",
    "\n",
    "By the end of this assignment, you'll be able to do the following in TensorFlow 2.3:\n",
    "\n",
    "* Use `tf.Variable` to modify the state of a variable\n",
    "* Explain the difference between a variable and a constant\n",
    "* Train a Neural Network on a TensorFlow dataset\n",
    "\n",
    "Programming frameworks like TensorFlow not only cut down on time spent coding, but can also perform optimizations that speed up the code itself. \n",
    "\n",
    "## Important Note on Submission to the AutoGrader\n",
    "\n",
    "Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:\n",
    "\n",
    "1. You have not added any _extra_ `print` statement(s) in the assignment.\n",
    "2. You have not added any _extra_ code cell(s) in the assignment.\n",
    "3. You have not changed any of the function parameters.\n",
    "4. You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.\n",
    "5. You are not changing the assignment code where it is not required, like creating _extra_ variables.\n",
    "\n",
    "If you do any of the following, you will get something like, `Grader not found` (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don't remember the changes you have made, you can get a fresh copy of the assignment by following these [instructions](https://www.coursera.org/learn/deep-neural-network/supplement/QWEnZ/h-ow-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1- Packages](#1)\n",
    "    - [1.1 - Checking TensorFlow Version](#1-1)\n",
    "- [2 - Basic Optimization with GradientTape](#2)\n",
    "    - [2.1 - Linear Function](#2-1)\n",
    "        - [Exercise 1 - linear_function](#ex-1)\n",
    "    - [2.2 - Computing the Sigmoid](#2-2)\n",
    "        - [Exercise 2 - sigmoid](#ex-2)\n",
    "    - [2.3 - Using One Hot Encodings](#2-3)\n",
    "        - [Exercise 3 - one_hot_matrix](#ex-3)\n",
    "    - [2.4 - Initialize the Parameters](#2-4)\n",
    "        - [Exercise 4 - initialize_parameters](#ex-4)\n",
    "- [3 - Building Your First Neural Network in TensorFlow](#3)\n",
    "    - [3.1 - Implement Forward Propagation](#3-1)\n",
    "        - [Exercise 5 - forward_propagation](#ex-5)\n",
    "    - [3.2 Compute the Total Loss](#3-2)\n",
    "        - [Exercise 6 - compute_total_loss](#ex-6)\n",
    "    - [3.3 - Train the Model](#3-3)\n",
    "- [4 - Bibliography](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 20:13:40.383030: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-15 20:13:40.386215: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-15 20:13:40.395349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-15 20:13:40.409700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-15 20:13:40.413966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-15 20:13:40.425716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 20:13:41.536743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from tensorflow.python.ops.resource_variable_ops import ResourceVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 - Checking TensorFlow Version \n",
    "\n",
    "You will be using v2.3 for this assignment, for maximum speed and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Basic Optimization with GradientTape\n",
    "\n",
    "The beauty of TensorFlow 2 is in its simplicity. Basically, all you need to do is implement forward propagation through a computational graph. TensorFlow will compute the derivatives for you, by moving backwards through the graph recorded with `GradientTape`. All that's left for you to do then is specify the cost function and optimizer you want to use! \n",
    "\n",
    "When writing a TensorFlow program, the main object to get used and transformed is the `tf.Tensor`. These tensors are the TensorFlow equivalent of Numpy arrays, i.e. multidimensional arrays of a given data type that also contain information about the computational graph.\n",
    "\n",
    "Below, you'll use `tf.Variable` to store the state of your variables. Variables can only be created once as its initial value defines the variable shape and type. Additionally, the `dtype` arg in `tf.Variable` can be set to allow data to be converted to that type. But if none is specified, either the datatype will be kept if the initial value is a Tensor, or `convert_to_tensor` will decide. It's generally best for you to specify directly, so nothing breaks!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you'll call the TensorFlow dataset created on a HDF5 file, which you can use in place of a Numpy array to store your datasets. You can think of this as a TensorFlow data generator! \n",
    "\n",
    "You will use the Hand sign data set, that is composed of images with shape 64x64x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (2062, 64, 64)\n",
      "Shape of Y: (2062, 10)\n",
      "Datasets have been converted and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "# Assuming you have downloaded and extracted the dataset to the appropriate directory\n",
    "X = np.load('datasets/X.npy')\n",
    "Y = np.load('datasets/Y.npy')\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "\n",
    "\n",
    "# Ensure data consistency\n",
    "if len(X) != len(Y):\n",
    "    raise ValueError(f\"Inconsistent dataset sizes: X has {len(X)} samples, Y has {len(Y)} samples\")\n",
    "\n",
    "# Preprocess the data\n",
    "# Normalize the images\n",
    "X = X / 255.0\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training set to an HDF5 file\n",
    "with h5py.File('train_signs.h5', 'w') as f:\n",
    "    f.create_dataset('train_set_x', data=X_train)\n",
    "    f.create_dataset('train_set_y', data=Y_train)\n",
    "\n",
    "# Save the test set to an HDF5 file\n",
    "with h5py.File('test_signs.h5', 'w') as f:\n",
    "    f.create_dataset('test_set_x', data=X_test)\n",
    "    f.create_dataset('test_set_y', data=Y_test)\n",
    "\n",
    "print(\"Datasets have been converted and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "test_dataset = h5py.File('datasets/test_signs.h5', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_x'])\n",
    "y_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_y'])\n",
    "\n",
    "x_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_x'])\n",
    "y_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since TensorFlow Datasets are generators, you can't access directly the contents unless you iterate over them in a for loop, or by explicitly creating a Python iterator using `iter` and consuming its\n",
    "elements using `next`. Also, you can inspect the `shape` and `dtype` of each element using the `element_spec` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(64, 64), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00219915 0.00221453 0.00221453 ... 0.00212226 0.00215302 0.00213764]\n",
      " [0.00219915 0.00224529 0.00226067 ... 0.00219915 0.00219915 0.0021684 ]\n",
      " [0.00221453 0.00226067 0.00227605 ... 0.00224529 0.00222991 0.00218378]\n",
      " ...\n",
      " [0.00201461 0.00202999 0.00202999 ... 0.00193772 0.00193772 0.00190696]\n",
      " [0.00199923 0.00199923 0.00199923 ... 0.00193772 0.00192234 0.0018762 ]\n",
      " [0.00196847 0.00196847 0.00198385 ... 0.00190696 0.00189158 0.00184544]], shape=(64, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that you'll be using during this assignment is a subset of the sign language digits. It contains six different classes representing the digits from 0 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor is unhashable. Instead, use tensor.ref() as the key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m unique_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m y_train:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43munique_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert numpy array to tuple\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_labels)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:365\u001b[0m, in \u001b[0;36m_EagerTensorBase.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;66;03m# EagerTensors are never hashable.\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor is unhashable. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead, use tensor.ref() as the key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor is unhashable. Instead, use tensor.ref() as the key."
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for element in y_train:\n",
    "    unique_labels.add(tuple(element))  # Convert numpy array to tuple\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see some of the images in the dataset by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_iter = iter(x_train)\n",
    "labels_iter = iter(y_train)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(next(images_iter).numpy().astype(\"uint8\"))\n",
    "    plt.title(next(labels_iter).numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/mnt/data/train_signs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the data from HDF5 files\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/data/train_signs.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_set_x\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n\u001b[1;32m      9\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_set_y\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/mnt/data/train_signs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from HDF5 files\n",
    "with h5py.File('/mnt/data/train_signs.h5', 'r') as f:\n",
    "    x_train = f['train_set_x'][:]\n",
    "    y_train = f['train_set_y'][:]\n",
    "\n",
    "with h5py.File('/mnt/data/test_signs.h5', 'r') as f:\n",
    "    x_test = f['test_set_x'][:]\n",
    "    y_test = f['test_set_y'][:]\n",
    "\n",
    "# Verify shapes\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"Y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", x_test.shape)\n",
    "print(\"Y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one more additional difference between TensorFlow datasets and Numpy arrays: If you need to transform one, you would invoke the `map` method to apply the function passed as an argument to each of the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    \"\"\"\n",
    "    Transform an image into a tensor of shape (64 * 64 * 3, )\n",
    "    and normalize its components.\n",
    "    \n",
    "    Arguments\n",
    "    image - Tensor.\n",
    "    \n",
    "    Returns: \n",
    "    result -- Transformed tensor \n",
    "    \"\"\"\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, [-1,])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = x_train.map(normalize)\n",
    "new_test = x_test.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(4096,), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[8.6241344e-06 8.6844429e-06 8.6844429e-06 ... 7.4782702e-06 7.4179616e-06\n",
      " 7.2370358e-06], shape=(4096,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 - Linear Function\n",
    "\n",
    "Let's begin this programming exercise by computing the following equation: $Y = WX + b$, where $W$ and $X$ are random matrices and b is a random vector. \n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - linear_function\n",
    "\n",
    "Compute $WX + b$ where $W, X$, and $b$ are drawn from a random normal distribution. W is of shape (4, 3), X is (3,1) and b is (4,1). As an example, this is how to define a constant X with the shape (3,1):\n",
    "```python\n",
    "X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "\n",
    "```\n",
    "Note that the difference between `tf.constant` and `tf.Variable` is that you can modify the state of a `tf.Variable` but cannot change the state of a `tf.constant`.\n",
    "\n",
    "You might find the following functions helpful: \n",
    "- tf.matmul(..., ...) to do a matrix multiplication\n",
    "- tf.add(..., ...) to do an addition\n",
    "- np.random.randn(...) to initialize randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "397d354ecaa1a28936096002cde11279",
     "grade": false,
     "grade_id": "cell-002e5736767021c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_function\n",
    "\n",
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implements a linear function: \n",
    "            Initializes X to be a random tensor of shape (3,1)\n",
    "            Initializes W to be a random tensor of shape (4,3)\n",
    "            Initializes b to be a random tensor of shape (4,1)\n",
    "    Returns: \n",
    "    result -- Y = WX + b \n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Note, to ensure that the \"random\" numbers generated match the expected results,\n",
    "    please create the variables in the order given in the starting code below.\n",
    "    (Do not re-arrange the order).\n",
    "    \"\"\"\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.Variable(np.random.randn(4,3), name = \"W\")\n",
    "    b = tf.Variable(np.random.randn(4,1), name = \"b\")\n",
    "    Y = tf.add(tf.matmul(W, X), b)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3526a7fd39649d2a6516031720e46748",
     "grade": true,
     "grade_id": "cell-b4318ea155f136ab",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]], shape=(4, 1), dtype=float64)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "result = linear_function()\n",
    "print(result)\n",
    "\n",
    "assert type(result) == EagerTensor, \"Use the TensorFlow API\"\n",
    "assert np.allclose(result, [[-2.15657382], [ 2.95891446], [-1.08926781], [-0.84538042]]), \"Error\"\n",
    "print(\"\\033[92mAll test passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "result = \n",
    "[[-2.15657382]\n",
    " [ 2.95891446]\n",
    " [-1.08926781]\n",
    " [-0.84538042]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Computing the Sigmoid \n",
    "Amazing! You just implemented a linear function. TensorFlow offers a variety of commonly used neural network functions like `tf.sigmoid` and `tf.softmax`.\n",
    "\n",
    "For this exercise, compute the sigmoid of z. \n",
    "\n",
    "In this exercise, you will: Cast your tensor to type `float32` using `tf.cast`, then compute the sigmoid using `tf.keras.activations.sigmoid`. \n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - sigmoid\n",
    "\n",
    "Implement the sigmoid function below. You should use the following: \n",
    "\n",
    "- `tf.cast(\"...\", tf.float32)`\n",
    "- `tf.keras.activations.sigmoid(\"...\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00b8d3d2338bb2ed68c9e316e5de9581",
     "grade": false,
     "grade_id": "cell-038bb4b7e61dd070",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "    \n",
    "    Returns: \n",
    "    a -- (tf.float32) the sigmoid of z\n",
    "    \"\"\"\n",
    "    # tf.keras.activations.sigmoid requires float16, float32, float64, complex64, or complex128.\n",
    "    \n",
    "    # (approx. 2 lines)\n",
    "    # z = ...\n",
    "    # a = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    z = tf.cast(z,tf.float32)\n",
    "    a = tf.keras.activations.sigmoid(z)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad1c73949744ba2205a0ad0d6f395915",
     "grade": true,
     "grade_id": "cell-a04f348c3fdbc2f2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "dtype: <dtype: 'float32'>\n",
      "sigmoid(-1) = tf.Tensor(0.26894143, shape=(), dtype=float32)\n",
      "sigmoid(0) = tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "sigmoid(12) = tf.Tensor(0.99999386, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sigmoid(\u001b[38;5;241m12\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.9999939\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92mAll test passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43msigmoid_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36msigmoid_test\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sigmoid(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sigmoid(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.26894143\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sigmoid(\u001b[38;5;241m12\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.9999939\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92mAll test passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Error"
     ]
    }
   ],
   "source": [
    "result = sigmoid(-1)\n",
    "print (\"type: \" + str(type(result)))\n",
    "print (\"dtype: \" + str(result.dtype))\n",
    "print (\"sigmoid(-1) = \" + str(result))\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0.0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))\n",
    "\n",
    "def sigmoid_test(target):\n",
    "    result = target(0)\n",
    "    assert(type(result) == EagerTensor)\n",
    "    assert (result.dtype == tf.float32)\n",
    "    assert sigmoid(0) == 0.5, \"Error\"\n",
    "    assert sigmoid(-1) == 0.26894143, \"Error\"\n",
    "    assert sigmoid(12) == 0.9999939, \"Error\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table>\n",
    "<tr> \n",
    "<td>\n",
    "type\n",
    "</td>\n",
    "<td>\n",
    "class 'tensorflow.python.framework.ops.EagerTensor'\n",
    "</td>\n",
    "</tr><tr> \n",
    "<td>\n",
    "dtype\n",
    "</td>\n",
    "<td>\n",
    "\"dtype: 'float32'\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "Sigmoid(-1)\n",
    "</td>\n",
    "<td>\n",
    "0.2689414\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "Sigmoid(0)\n",
    "</td>\n",
    "<td>\n",
    "0.5\n",
    "</td>\n",
    "</tr>\n",
    "<tr> \n",
    "<td>\n",
    "Sigmoid(12)\n",
    "</td>\n",
    "<td>\n",
    "0.999994\n",
    "</td>\n",
    "</tr> \n",
    "\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-3'></a>\n",
    "### 2.3 - Using One Hot Encodings\n",
    "\n",
    "Many times in deep learning you will have a $Y$ vector with numbers ranging from $0$ to $C-1$, where $C$ is the number of classes. If $C$ is for example 4, then you might have the following y vector which you will need to convert like this:\n",
    "\n",
    "\n",
    "<img src=\"images/onehot.png\" style=\"width:600px;height:150px;\">\n",
    "\n",
    "This is called \"one hot\" encoding, because in the converted representation, exactly one element of each column is \"hot\" (meaning set to 1). To do this conversion in numpy, you might have to write a few lines of code. In TensorFlow, you can use one line of code: \n",
    "\n",
    "- [tf.one_hot(labels, depth, axis=0)](https://www.tensorflow.org/api_docs/python/tf/one_hot)\n",
    "\n",
    "`axis=0` indicates the new axis is created at dimension 0\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - one_hot_matrix\n",
    "\n",
    "Implement the function below to take one label and the total number of classes $C$, and return the one hot encoding in a column wise matrix. Use `tf.one_hot()` to do this, and `tf.reshape()` to reshape your one hot tensor! \n",
    "\n",
    "- `tf.reshape(tensor, shape)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1649, 64, 64)\n",
      "Y_train shape: (1649, 10)\n",
      "X_test shape: (413, 64, 64)\n",
      "Y_test shape: (413, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from HDF5 files\n",
    "with h5py.File('datasets/train_signs.h5', 'r') as f:\n",
    "    x_train = f['train_set_x'][:]\n",
    "    y_train = f['train_set_y'][:]\n",
    "\n",
    "with h5py.File('datasets/test_signs.h5', 'r') as f:\n",
    "    x_test = f['test_set_x'][:]\n",
    "    y_test = f['test_set_y'][:]\n",
    "\n",
    "# Verify shapes\n",
    "print(\"X_train shape:\", x_train.shape)\n",
    "print(\"Y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", x_test.shape)\n",
    "print(\"Y_test shape:\", y_test.shape)\n",
    "\n",
    "# Visualizing some examples\n",
    "images_iter = iter(x_train)\n",
    "labels_iter = iter(y_train)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(next(images_iter).astype(\"uint8\"))\n",
    "    plt.title(next(labels_iter).astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "288633a50973dc8e0a9e6d5c3348c3e3",
     "grade": false,
     "grade_id": "cell-15d9db613d8007bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n",
      "Test 2: tf.Tensor([0. 0. 1. 0.], shape=(4,), dtype=float32)\n",
      "\u001b[92mAll test passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 20:20:49.428581: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Y_train shape: (1649, 10, 10)\n",
      "New Y_test shape: (413, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_matrix(label, depth=10):\n",
    "    \"\"\"\n",
    "    Computes the one hot encoding for a single label.\n",
    "    \n",
    "    Arguments:\n",
    "        label --  (int) Categorical label\n",
    "        depth --  (int) Number of different classes that label can take\n",
    "    \n",
    "    Returns:\n",
    "        one_hot -- tf.Tensor A single-column matrix with the one hot encoding.\n",
    "    \"\"\"\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    one_hot = tf.one_hot(label, depth, axis=-1)\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_matrix_test(target):\n",
    "    label = tf.constant(1)\n",
    "    depth = 4\n",
    "    result = target(label, depth)\n",
    "    print(\"Test 1:\", result)\n",
    "    assert result.shape[0] == depth, \"Use the parameter depth\"\n",
    "    assert np.allclose(result, [0., 1., 0., 0.]), \"Wrong output. Use tf.one_hot\"\n",
    "    label_2 = tf.constant(2)\n",
    "    result = target(label_2, depth)\n",
    "    print(\"Test 2:\", result)\n",
    "    assert result.shape[0] == depth, \"Use the parameter depth\"\n",
    "    assert np.allclose(result, [0., 0., 1., 0.]), \"Wrong output. Use tf.reshape as instructed\"\n",
    "    \n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "# Running the test\n",
    "one_hot_matrix_test(one_hot_matrix)\n",
    "\n",
    "# Apply one-hot encoding to y_train and y_test\n",
    "new_y_train = np.array([one_hot_matrix(y, depth=10).numpy() for y in y_train])\n",
    "new_y_test = np.array([one_hot_matrix(y, depth=10).numpy() for y in y_test])\n",
    "\n",
    "# Verify shapes\n",
    "print(\"New Y_train shape:\", new_y_train.shape)\n",
    "print(\"New Y_test shape:\", new_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```\n",
    "Test 1: tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n",
    "Test 2: tf.Tensor([0. 0. 1. 0.], shape=(4,), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_y_test \u001b[38;5;241m=\u001b[39m \u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(one_hot_matrix)\n\u001b[1;32m      2\u001b[0m new_y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mmap(one_hot_matrix)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "new_y_test = y_test.map(one_hot_matrix)\n",
    "new_y_train = y_train.map(one_hot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mnew_y_test\u001b[49m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2-4'></a>\n",
    "### 2.4 - Initialize the Parameters \n",
    "\n",
    "Now you'll initialize a vector of numbers with the Glorot initializer. The function you'll be calling is `tf.keras.initializers.GlorotNormal`, which draws samples from a truncated normal distribution centered on 0, with `stddev = sqrt(2 / (fan_in + fan_out))`, where `fan_in` is the number of input units and `fan_out` is the number of output units, both in the weight tensor. \n",
    "\n",
    "To initialize with zeros or ones you could use `tf.zeros()` or `tf.ones()` instead. \n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Exercise 4 - initialize_parameters\n",
    "\n",
    "Implement the function below to take in a shape and to return an array of numbers using the GlorotNormal initializer. \n",
    "\n",
    " - `tf.keras.initializers.GlorotNormal(seed=1)`\n",
    " - `tf.Variable(initializer(shape=())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da48416c74797c83152e1080b08afb9d",
     "grade": false,
     "grade_id": "cell-1d5716c48a16debf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with TensorFlow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "                                \n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=1)   \n",
    "    #(approx. 6 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # W3 = ...\n",
    "    # b3 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = tf.Variable(initializer(shape=(25, 12288)))\n",
    "    b1 = tf.Variable(initializer(shape=(25, 1)))\n",
    "    W2 = tf.Variable(initializer(shape=(12, 25)))\n",
    "    b2 = tf.Variable(initializer(shape=(12, 1)))\n",
    "    W3 = tf.Variable(initializer(shape=(6, 12)))\n",
    "    b3 = tf.Variable(initializer(shape=(6, 1)))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd3fe0b5ed777771156c071d9373e47a",
     "grade": true,
     "grade_id": "cell-11012e1fada40919",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters_test(target):\n",
    "    parameters = target()\n",
    "\n",
    "    values = {\"W1\": (25, 12288),\n",
    "              \"b1\": (25, 1),\n",
    "              \"W2\": (12, 25),\n",
    "              \"b2\": (12, 1),\n",
    "              \"W3\": (6, 12),\n",
    "              \"b3\": (6, 1)}\n",
    "\n",
    "    for key in parameters:\n",
    "        print(f\"{key} shape: {tuple(parameters[key].shape)}\")\n",
    "        assert type(parameters[key]) == ResourceVariable, \"All parameter must be created using tf.Variable\"\n",
    "        assert tuple(parameters[key].shape) == values[key], f\"{key}: wrong shape\"\n",
    "        assert np.abs(np.mean(parameters[key].numpy())) < 0.5,  f\"{key}: Use the GlorotNormal initializer\"\n",
    "        assert np.std(parameters[key].numpy()) > 0 and np.std(parameters[key].numpy()) < 1, f\"{key}: Use the GlorotNormal initializer\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "    \n",
    "initialize_parameters_test(initialize_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```\n",
    "W1 shape: (25, 12288)\n",
    "b1 shape: (25, 1)\n",
    "W2 shape: (12, 25)\n",
    "b2 shape: (12, 1)\n",
    "W3 shape: (6, 12)\n",
    "b3 shape: (6, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Building Your First Neural Network in TensorFlow\n",
    "\n",
    "In this part of the assignment you will build a neural network using TensorFlow. Remember that there are two parts to implementing a TensorFlow model:\n",
    "\n",
    "- Implement forward propagation\n",
    "- Retrieve the gradients and train the model\n",
    "\n",
    "Let's get into it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - Implement Forward Propagation \n",
    "\n",
    "One of TensorFlow's great strengths lies in the fact that you only need to implement the forward propagation function and it will keep track of the operations you did to calculate the back propagation automatically.  \n",
    "\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - forward_propagation\n",
    "\n",
    "Implement the `forward_propagation` function.\n",
    "\n",
    "**Note** Use only the TF API. \n",
    "\n",
    "- tf.math.add\n",
    "- tf.linalg.matmul\n",
    "- tf.keras.activations.relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e52024ce85f80538e02ad44ff9a6e334",
     "grade": false,
     "grade_id": "cell-23b6d82b3443e298",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    #(approx. 5 lines)                   # Numpy Equivalents:\n",
    "    # Z1 = ...                           # Z1 = np.dot(W1, X) + b1\n",
    "    # A1 = ...                           # A1 = relu(Z1)\n",
    "    # Z2 = ...                           # Z2 = np.dot(W2, A1) + b2\n",
    "    # A2 = ...                           # A2 = relu(Z2)\n",
    "    # Z3 = ...                           # Z3 = np.dot(W3, A2) + b3\n",
    "    # YOUR CODE STARTS HERE\n",
    "    Z1 = tf.math.add(tf.linalg.matmul(W1,X),b1)\n",
    "    A1 = tf.keras.activations.relu(Z1)\n",
    "    Z2 = tf.math.add(tf.linalg.matmul(W2,A1),b2)\n",
    "    A2 = tf.keras.activations.relu(Z2)\n",
    "    Z3 = tf.math.add(tf.linalg.matmul(W3,A2),b3)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adf252febb4ae71156322e225433ae83",
     "grade": true,
     "grade_id": "cell-728b002a6a88ceb1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def forward_propagation_test(target, examples):\n",
    "    minibatches = examples.batch(2)\n",
    "    parametersk = initialize_parameters()\n",
    "    W1 = parametersk['W1']\n",
    "    b1 = parametersk['b1']\n",
    "    W2 = parametersk['W2']\n",
    "    b2 = parametersk['b2']\n",
    "    W3 = parametersk['W3']\n",
    "    b3 = parametersk['b3']\n",
    "    index = 0\n",
    "    minibatch = list(minibatches)[0]\n",
    "    with tf.GradientTape() as tape:\n",
    "        forward_pass = target(tf.transpose(minibatch), parametersk)\n",
    "        print(forward_pass)\n",
    "        fake_cost = tf.reduce_mean(forward_pass - np.ones((6,2)))\n",
    "\n",
    "        assert type(forward_pass) == EagerTensor, \"Your output is not a tensor\"\n",
    "        assert forward_pass.shape == (6, 2), \"Last layer must use W3 and b3\"\n",
    "        assert np.allclose(forward_pass, \n",
    "                           [[-0.13430887,  0.14086473],\n",
    "                            [ 0.21588647, -0.02582335],\n",
    "                            [ 0.7059658,   0.6484556 ],\n",
    "                            [-1.1260961,  -0.9329492 ],\n",
    "                            [-0.20181894, -0.3382722 ],\n",
    "                            [ 0.9558965,   0.94167566]]), \"Output does not match\"\n",
    "    index = index + 1\n",
    "    trainable_variables = [W1, b1, W2, b2, W3, b3]\n",
    "    grads = tape.gradient(fake_cost, trainable_variables)\n",
    "    assert not(None in grads), \"Wrong gradients. It could be due to the use of tf.Variable whithin forward_propagation\"\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "forward_propagation_test(forward_propagation, new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```\n",
    "tf.Tensor(\n",
    "[[-0.13430887  0.14086473]\n",
    " [ 0.21588647 -0.02582335]\n",
    " [ 0.7059658   0.6484556 ]\n",
    " [-1.1260961  -0.9329492 ]\n",
    " [-0.20181894 -0.3382722 ]\n",
    " [ 0.9558965   0.94167566]], shape=(6, 2), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 Compute the Total Loss\n",
    "\n",
    "All you have to do now is define the loss function that you're going to use. For this case, since we have a classification problem with 6 labels, a categorical cross entropy will work! \n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Exercise 6 -  compute_total_loss\n",
    "\n",
    "Implement the total loss function below. You will use it to compute the total loss of a batch of samples. With this convenient function, you can sum the losses across many batches, and divide the sum by the total number of samples to get the cost value. \n",
    "- It's important to note that the \"`y_pred`\" and \"`y_true`\" inputs of [tf.keras.losses.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy) are expected to be of shape (number of examples, num_classes). \n",
    "\n",
    "- `tf.reduce_sum` does the summation over the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb8126e4c0e3f4e08dd6ba21cec57b6e",
     "grade": false,
     "grade_id": "cell-e6cc4d7fefeed231",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_total_loss \n",
    "\n",
    "def compute_total_loss(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the total loss\n",
    "    \n",
    "    Arguments:\n",
    "    logits -- output of forward propagation (output of the last LINEAR unit), of shape (6, num_examples)\n",
    "    labels -- \"true\" labels vector, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    total_loss - Tensor of the total loss value\n",
    "    \"\"\"\n",
    "    \n",
    "    #(1 line of code)\n",
    "    # total_loss = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    total_loss = tf.reduce_sum(tf.keras.metrics.categorical_crossentropy(tf.transpose(labels),tf.transpose(logits),from_logits=True))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19e0a72fc52c3b9f64ca7df79bbf766b",
     "grade": true,
     "grade_id": "cell-9bf72affa2e7b1b5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_total_loss_test(target, Y):\n",
    "    pred = tf.constant([[ 2.4048107,   5.0334096 ],\n",
    "             [-0.7921977,  -4.1523376 ],\n",
    "             [ 0.9447198,  -0.46802214],\n",
    "             [ 1.158121,    3.9810789 ],\n",
    "             [ 4.768706,    2.3220146 ],\n",
    "             [ 6.1481323,   3.909829  ]])\n",
    "    minibatches = Y.batch(2)\n",
    "    for minibatch in minibatches:\n",
    "        result = target(pred, tf.transpose(minibatch))\n",
    "        break\n",
    "        \n",
    "    print(result)\n",
    "    assert(type(result) == EagerTensor), \"Use the TensorFlow API\"\n",
    "    assert (np.abs(result - (0.50722074 + 1.1133534) / 2.0) < 1e-7), \"Test does not match. Did you get the reduce sum of your loss functions?\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "compute_total_loss_test(compute_total_loss, new_y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```\n",
    "tf.Tensor(0.810287, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - Train the Model\n",
    "\n",
    "Let's talk optimizers. You'll specify the type of optimizer in one line, in this case `tf.keras.optimizers.Adam` (though you can use others such as SGD), and then call it within the training loop. \n",
    "\n",
    "Notice the `tape.gradient` function: this allows you to retrieve the operations recorded for automatic differentiation inside the `GradientTape` block. Then, calling the optimizer method `apply_gradients`, will apply the optimizer's update rules to each trainable parameter. At the end of this assignment, you'll find some documentation that explains this more in detail, but for now, a simple explanation will do. ;) \n",
    "\n",
    "\n",
    "Here you should take note of an important extra step that's been added to the batch training process: \n",
    "\n",
    "- `tf.Data.dataset = dataset.prefetch(8)` \n",
    "\n",
    "What this does is prevent a memory bottleneck that can occur when reading from disk. `prefetch()` sets aside some data and keeps it ready for when it's needed. It does this by creating a source dataset from your input data, applying a transformation to preprocess the data, then iterating over the dataset the specified number of elements at a time. This works because the iteration is streaming, so the data doesn't need to fit into the memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.0001,\n",
    "          num_epochs=1500, minibatch_size=32, print_cost=True):\n",
    "    costs = []  # To keep track of the cost\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    # Initialize your parameters\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    # The CategoricalAccuracy will track the accuracy for this multiclass problem\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((X_train, Y_train))\n",
    "    test_dataset = tf.data.Dataset.zip((X_test, Y_test))\n",
    "\n",
    "    # We can get the number of elements of a dataset using the cardinality method\n",
    "    m = dataset.cardinality().numpy()\n",
    "\n",
    "    minibatches = dataset.batch(minibatch_size).prefetch(8)\n",
    "    test_minibatches = test_dataset.batch(minibatch_size).prefetch(8)\n",
    "\n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        epoch_total_loss = 0.\n",
    "\n",
    "        #We need to reset object to start measuring from 0 the accuracy each epoch\n",
    "        train_accuracy.reset_state()\n",
    "\n",
    "        for (minibatch_X, minibatch_Y) in minibatches:\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # 1. predict\n",
    "                Z3 = forward_propagation(tf.transpose(minibatch_X), parameters)\n",
    "\n",
    "                # 2. loss\n",
    "                minibatch_total_loss = compute_total_loss(Z3, tf.transpose(minibatch_Y))\n",
    "\n",
    "            # We accumulate the accuracy of all the batches\n",
    "            train_accuracy.update_state(minibatch_Y, tf.transpose(Z3))\n",
    "\n",
    "            trainable_variables = [W1, b1, W2, b2, W3, b3]\n",
    "            grads = tape.gradient(minibatch_total_loss, trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "            epoch_total_loss += minibatch_total_loss\n",
    "\n",
    "        # We divide the epoch total loss over the number of samples\n",
    "        epoch_total_loss /= m\n",
    "\n",
    "        # Print the cost every 10 epochs\n",
    "        if print_cost == True and epoch % 10 == 0:\n",
    "            print(\"Cost after epoch %i: %f\" % (epoch, epoch_total_loss))\n",
    "            print(\"Train accuracy:\", train_accuracy.result())\n",
    "\n",
    "            # We evaluate the test set every 10 epochs to avoid computational overhead\n",
    "            for (minibatch_X, minibatch_Y) in test_minibatches:\n",
    "                Z3 = forward_propagation(tf.transpose(minibatch_X), parameters)\n",
    "                test_accuracy.update_state(minibatch_Y, tf.transpose(Z3))\n",
    "            print(\"Test_accuracy:\", test_accuracy.result())\n",
    "\n",
    "            costs.append(epoch_total_loss)\n",
    "            train_acc.append(train_accuracy.result().numpy())\n",
    "            test_acc.append(test_accuracy.result().numpy())\n",
    "            test_accuracy.reset_state()\n",
    "\n",
    "    return parameters, costs, train_acc, test_acc\n",
    "# Ensure your data is in the correct format before passing it to the model\n",
    "parameters, costs, train_acc, test_acc = model(new_train, new_y_train, new_test, new_y_test, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "```\n",
    "Cost after epoch 0: 1.830244\n",
    "Train accuracy: tf.Tensor(0.17037037, shape=(), dtype=float32)\n",
    "Test_accuracy: tf.Tensor(0.2, shape=(), dtype=float32)\n",
    "Cost after epoch 10: 1.552390\n",
    "Train accuracy: tf.Tensor(0.35925925, shape=(), dtype=float32)\n",
    "Test_accuracy: tf.Tensor(0.30833334, shape=(), dtype=float32)\n",
    "...\n",
    "```\n",
    "Numbers you get can be different, just check that your loss is going down and your accuracy going up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cost\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per fives)')\n",
    "plt.title(\"Learning rate =\" + str(0.0001))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train accuracy\n",
    "plt.plot(np.squeeze(train_acc))\n",
    "plt.ylabel('Train Accuracy')\n",
    "plt.xlabel('iterations (per fives)')\n",
    "plt.title(\"Learning rate =\" + str(0.0001))\n",
    "# Plot the test accuracy\n",
    "plt.plot(np.squeeze(test_acc))\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('iterations (per fives)')\n",
    "plt.title(\"Learning rate =\" + str(0.0001))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**! You've made it to the end of this assignment, and to the end of this week's material. Amazing work building a neural network in TensorFlow 2.3! \n",
    "\n",
    "Here's a quick recap of all you just achieved:\n",
    "\n",
    "- Used `tf.Variable` to modify your variables\n",
    "- Trained a Neural Network on a TensorFlow dataset\n",
    "\n",
    "You are now able to harness the power of TensorFlow to create cool things, faster. Nice! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Bibliography \n",
    "\n",
    "In this assignment, you were introducted to `tf.GradientTape`, which records operations for differentation. Here are a couple of resources for diving deeper into what it does and why: \n",
    "\n",
    "Introduction to Gradients and Automatic Differentiation: \n",
    "https://www.tensorflow.org/guide/autodiff \n",
    "\n",
    "GradientTape documentation:\n",
    "https://www.tensorflow.org/api_docs/python/tf/GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
